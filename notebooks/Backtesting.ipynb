{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid19.models import SEIRBayes\n",
    "from covid19.estimation import ReproductionNumber\n",
    "from covid19.data import load_cases, load_population\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tbats import TBATS\n",
    "\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "parallel = Parallel(n_jobs=CPU_COUNT, verbose=3)\n",
    "\n",
    "SAMPLE_SIZE = 10_000\n",
    "DEFAULT_SEIR_PARAMS = dict(\n",
    "    gamma_inv_dist=(7, 13, 0.95, \"lognorm\"),\n",
    "    alpha_inv_dist=(4, 7, 0.95, \"lognorm\"),\n",
    "    fator_subr=20 # subnot / (1-assint)\n",
    ")\n",
    "one_day = pd.Timedelta('1D')\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.rcParams['image.cmap'] = 'Dark2'\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_active_cases(cases, gamma_sup):\n",
    "    return (\n",
    "        cases\n",
    "        .assign(\n",
    "            estimatedActiveCases=lambda x: (\n",
    "                x[\"newCases\"]\n",
    "                .rolling(window=int(gamma_sup), min_periods=1)\n",
    "                .sum()\n",
    "            )\n",
    "        )\n",
    "        .assign(\n",
    "            estimatedRemovedCases=lambda x: (\n",
    "                x[\"totalCases\"] - x[\"estimatedActiveCases\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def estimate_r0_mean(cases):\n",
    "    incidence = (cases['newCases']\n",
    "                 .rename('incidence')\n",
    "                 .reset_index()\n",
    "                 .rename(columns={'date': 'dates'}))\n",
    "    dynamic_window_width = min(len(incidence) - 2, 14)\n",
    "    Rt = ReproductionNumber(\n",
    "        incidence=incidence,\n",
    "        prior_shape=5.12,\n",
    "        prior_scale=0.64,\n",
    "        si_pars={\"mean\": 4.89, \"sd\": 1.48},\n",
    "        window_width=dynamic_window_width,\n",
    "    )\n",
    "    Rt.compute_posterior_parameters()\n",
    "    rt_samples = Rt.sample_from_posterior(sample_size=SAMPLE_SIZE)\n",
    "    return rt_samples[:, -1].mean()\n",
    "\n",
    "\n",
    "def mse(pred, true):\n",
    "    return np.sqrt((true - pred)\n",
    "                   .pipe(np.power, 2)\n",
    "                   .sum())\n",
    "\n",
    "\n",
    "def mape(pred, true):\n",
    "    return ((true - pred)\n",
    "            .abs()\n",
    "            .sum())/true.sum()\n",
    "\n",
    "\n",
    "def predict_tbats(y_train, len_test_period):\n",
    "    estimator = TBATS(\n",
    "        seasonal_periods=None,\n",
    "        use_arma_errors=None,\n",
    "        use_box_cox=None,\n",
    "        use_trend=None,\n",
    "        use_damped_trend=None,\n",
    "        show_warnings=False,\n",
    "    )\n",
    "    fitted_model = estimator.fit(y_train)\n",
    "    return fitted_model.forecast(steps=len_test_period)\n",
    "\n",
    "\n",
    "def run_and_plot_single_comparison_with_tbats(*args, **kwargs):\n",
    "    r = run_single(*args, **kwargs, return_series=True)\n",
    "    r_tbats = run_single(*args, **kwargs, return_series=True, use_tbats=True)\n",
    "    fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "    (r['df']\n",
    "     [['totalCases', 'AvgtotalCases_pred']]\n",
    "     .rename(columns={'totalCases': 'HistÃ³rico', \n",
    "                      'AvgtotalCases_pred': 'SEIR-Bayes'})\n",
    "     .plot\n",
    "     .line(ax=ax,\n",
    "           color = ['b', 'y'],\n",
    "           style=['-','--']))\n",
    "    (r_tbats['df']\n",
    "     ['AvgtotalCases_pred']\n",
    "     .rename('TBATS')\n",
    "     .plot\n",
    "     .line(ax=ax,\n",
    "           color='r',\n",
    "           style='--'))\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.fill_between(r['df'].index,\n",
    "                    r['df']['AvgtotalCases_pred'] - 3*r['df']['StdtotalCases_pred'],\n",
    "                    r['df']['AvgtotalCases_pred'] + 3*r['df']['StdtotalCases_pred'],\n",
    "                    color='y',\n",
    "                    alpha=0.3)\n",
    "    plt.title(f\"{kwargs['place']} @ t_max={kwargs['t_max']}, date={kwargs['date']}\")\n",
    "    plt.show()\n",
    "    r.pop('df')\n",
    "    r_tbats.pop('df')\n",
    "    return pd.DataFrame([r, r_tbats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.concat([load_cases('state'), load_cases('city')], axis=1)\n",
    "cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.concat([load_population('state'), load_population('city')], axis=0)\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train and test periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = (\n",
    "    (cases.loc(axis=1)[:, 'newCases'] > 100)\n",
    "    .loc(axis=1)[lambda df: df.any()]\n",
    "    .droplevel(1, axis=1)\n",
    "    .apply(lambda s: s.index[s.argmax()])\n",
    "    .rename('start_date')\n",
    ")\n",
    "\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dates(stride, start_date=start_date): \n",
    "    return (\n",
    "        start_date\n",
    "        .apply(lambda d: pd.date_range(d, 'now', freq=stride)[1:])\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "split_dates('15D')['SP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Cases dataframe with estimatedActiveCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_window = DEFAULT_SEIR_PARAMS['gamma_inv_dist'][1]\n",
    "\n",
    "cases_aug = pd.concat(\n",
    "    [(estimate_active_cases(cases[place], gamma_window)\n",
    "    .assign(place=place)\n",
    "    .set_index('place', append=True)\n",
    "    .unstack('place')\n",
    "    .swaplevel(0, 1, axis=1))\n",
    " for place in start_date.index], axis=1)\n",
    "\n",
    "cases_aug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single(**params):\n",
    "    try:\n",
    "        place, date, t_max = params['place'], params['date'], int(params['t_max'])\n",
    "        return_series = params.get('return_series', False)\n",
    "        use_tbats = params.get('use_tbats', False)\n",
    "        \n",
    "        date = pd.Timestamp(date)\n",
    "        N = population[place]\n",
    "        cases_aug_place = cases_aug[place]\n",
    "\n",
    "        train_start_date = start_date[place]\n",
    "        train_end_date = date\n",
    "        test_start_date = date + one_day\n",
    "        test_end_date = np.min([date + pd.Timedelta(f'{t_max}D'),\n",
    "                                cases_aug_place.index.max()])\n",
    "\n",
    "        train_period = f'{train_start_date.date()}:{train_end_date.date()}'\n",
    "        test_period = f'{test_start_date.date()}:{test_end_date.date()}'\n",
    "\n",
    "        cases_aug_train = cases_aug_place.loc[train_start_date:train_end_date]\n",
    "        cases_aug_test = cases_aug_place.loc[test_start_date:test_end_date]\n",
    "\n",
    "        n_test_points = int(cases_aug_test.shape[0])\n",
    "        n_train_points = int(cases_aug_train.shape[0])\n",
    "        \n",
    "        common_output = {\n",
    "            'place': place,\n",
    "            'train_period': train_period,\n",
    "            'test_period': test_period,\n",
    "            'n_test_points': n_test_points,\n",
    "            'n_train_points': n_train_points,\n",
    "            'model': 'TBATS' if use_tbats else 'SEIR-Bayes',\n",
    "            'date': date.date(),\n",
    "            't_max': t_max,\n",
    "        }\n",
    "        \n",
    "        if n_test_points < 7:\n",
    "            raise Exception('Not enough test points '\n",
    "                            f'({n_test_points}) @ {place} and {date.date()}')\n",
    "            \n",
    "        assert not cases_aug_test.index.isin(cases_aug_train.index).any()\n",
    "        assert all(cases_aug[train_start_date:test_end_date].index\n",
    "                   == cases_aug_train.index.tolist() + cases_aug_test.index.tolist())\n",
    "\n",
    "        if use_tbats:\n",
    "            avg_total_cases_pred = predict_tbats(cases_aug_train['totalCases'], t_max)\n",
    "            std_total_cases_pred = np.zeros_like(avg_total_cases_pred)\n",
    "        else:\n",
    "            I0 = cases_aug_train[\"estimatedActiveCases\"].iloc[-1]\n",
    "            r0 = estimate_r0_mean(cases_aug_train)\n",
    "            E0 = r0*I0\n",
    "            R0 = cases_aug_train[\"estimatedRemovedCases\"].iloc[-1]\n",
    "\n",
    "            model = CompartmentalModel(\n",
    "                NEIR0=(N, E0, I0, R0),\n",
    "                r0_dist=np.full(SAMPLE_SIZE, r0),\n",
    "                **DEFAULT_SEIR_PARAMS,\n",
    "                t_max=t_max,\n",
    "            )\n",
    "            _, _, I, R, _, _ = model.sample(SAMPLE_SIZE)\n",
    "            I /= DEFAULT_SEIR_PARAMS['fator_subr']\n",
    "            R /= DEFAULT_SEIR_PARAMS['fator_subr']\n",
    "            avg_total_cases_pred = (I + R).mean(axis=1)\n",
    "            std_total_cases_pred = (I + R).std(axis=1)\n",
    "\n",
    "        if return_series:\n",
    "            avg_total_cases_pred = pd.Series(avg_total_cases_pred,\n",
    "                                             index=pd.date_range(test_start_date, periods=t_max),\n",
    "                                             name='AvgtotalCases_pred')\n",
    "            std_total_cases_pred = pd.Series(std_total_cases_pred,\n",
    "                                             index=pd.date_range(test_start_date, periods=t_max),\n",
    "                                             name='StdtotalCases_pred')\n",
    "            cases_aug_place = pd.concat([avg_total_cases_pred, \n",
    "                                         std_total_cases_pred,\n",
    "                                         cases_aug_place], axis=1)\n",
    "        \n",
    "        return {\n",
    "            **common_output,\n",
    "            'mape': mape(avg_total_cases_pred[:n_test_points], cases_aug_test['totalCases']),\n",
    "            'mse': mse(avg_total_cases_pred[:n_test_points], cases_aug_test['totalCases']),\n",
    "            'df': cases_aug_place if return_series else None,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **common_output,\n",
    "            'exception': e,\n",
    "            'df': None\n",
    "        }\n",
    "\n",
    "# aqui vocÃªs podem adicionar mais casos de teste e rodar em paralelo\n",
    "metrics = parallel([delayed(run_single)(place=place,\n",
    "                                        date=date,\n",
    "                                        t_max=t_max,\n",
    "                                        use_tbats=use_tbats)\n",
    "                    for use_tbats in [True, False]\n",
    "                    for place in ['MG', 'SÃ£o Paulo/SP']\n",
    "                    for date in split_dates(stride='15D')[place]\n",
    "                    for t_max in [15, 60]])\n",
    "metrics = pd.DataFrame(metrics)\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - metrics['exception'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics\n",
    " .query(\"exception.isna()\")\n",
    " ['mape']\n",
    " .describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.query(\"exception.isna()\").corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics\n",
    " .query(\"exception.isna()\")\n",
    " .sort_values('mape')\n",
    " .drop_duplicates(subset=['place'])\n",
    " .nsmallest(20, 'mape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_plot_single_comparison_with_tbats(place='MG', t_max=30, date='2020-05-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics\n",
    " .groupby(['n_train_points', 'model'])\n",
    " ['mape']\n",
    " .mean()\n",
    " .unstack('model')\n",
    " .plot(style='o--', title='Average MAPE'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics\n",
    " .groupby(['n_test_points', 'model'])\n",
    " ['mape']\n",
    " .mean()\n",
    " .unstack('model')\n",
    " .plot(style='o--', title='Average MAPE'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics\n",
    " .groupby(['model', 't_max'])\n",
    " ['mape']\n",
    " .mean()\n",
    " .unstack('model')\n",
    " .plot(style='o--', title='Average MAPE'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics\n",
    " .groupby([metrics['n_test_points'] // 5, 'model'])\n",
    " ['mape']\n",
    " .mean()\n",
    " .unstack('model')\n",
    " .plot(style='o--', title='Average MAPE'))\n",
    "\n",
    "plt.xlabel('n_test_points // 5');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
